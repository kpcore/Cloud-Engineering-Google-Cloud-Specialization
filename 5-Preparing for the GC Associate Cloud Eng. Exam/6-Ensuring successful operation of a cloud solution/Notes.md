## 1. Managing Compute Engine resources

* Welcome to Preparing for the Associate Cloud Engineering Exam. This module will cover some concepts necessary for ensuring successful operation of a Cloud solution. This module is all about managing your Cloud resources, whether it's Compute Engine, Kubernetes Engine, App Engine, data solutions, network resources, or logging, and monitoring. Our first step on this particular part of the journey as managing Compute Engine Resources. Section 4.1 covers quite a lot of tasks needed to manage Compute Engine instances, as you can see. We won't have time in this course to go over all the tasks in this list, but let's begin by reviewing VM images in a very general way. You can use operating system images to create boot disks for your VM instances. You can use one of the following image types. Public images are provided and maintained by Google, open-source communities, and third-party vendors. By default, all projects have access to these images, and can use them to create instances. Custom images are available only to your project. You can create a custom image from boot disks and other images. Then use the custom image grid and instance. You can use most public images at no additional cost, but there are some premium images that do add additional cost to your instances. Custom images that you import to Compute Engine at no cost to your instances, but do incur an image storage charge, or you keep your custom image in your project. Some images are capable of running containers on Compute Engine. Support for Compute Engine provided public OS images are subject to the life cycle of the respective OS. Snapshots are incremental and automatically compressed, so you can create regular snapshots on a persistent disk faster in a much lower cost, than if you regularly created a full image of the disk. Incremental snapshots work in the following manner. The first successful snapshot of a persistent disk is a full snapshot that contains all the data on a persistent disk. The second snapshot only contains any new data or modify data since the first snapshot. They that hasn't changed since snapshot 1 isn't included. Instead snapshot 2 contains references to snapshot 1 for any unchanged data. Snapshot 3 contains any new, or changing it since snapshot 2, but won't contain any unchanged data from snapshot 1 or 2. Instead, snapshot 3 contains references to blocks and snapshot 1 and snapshot 2 for any unchanged data. This repeats for all subsequent snapshots of the persistent disk. Snapshots are always created based on the last successful snapshot taken. Compute Engine stores multiple copies of each snapshot across multiple locations with automatic checksums to ensure the integrity of your data. Use AIM roles to share snapshots across project. To see lists of snapshots available to a project, use the gcloud compute snapshots list command. To list information about a particular snapshot, such as the creation time, size, and source disc, use the gcloud compute snapshots describe command. A custom image is the boot disk image that you own and control access to. If you regularly update your custom images with newer configurations in software, you can group those images into an image family. The image family always points to the most recent image in that family, so your instance templates and scripts can use that image without having to update references to a specific image version. You can create disk images from the following sources: a persistent disk, even while that this is attached to an instance; a snapshot of a persistent disk; another image in your project; an image that is shared from another project, or compressed RAW image in Google Cloud Storage.

## 2. Managing Kubernetes Engine resources

* Our next section deals at managing Kubernetes Engine resources. In particular, we'll look a bit more closely at how to deploy and work with Kubernetes pods. A deployment represents a group of replicas of the same pod and keeps your pods running, even when nodes they run on fail. You could represent a component of an application or an entire App. In this case, the engine acts web server by default pods and deployment are only accessible inside your GKE cluster. To make them publicly available, you can connect a load balancer to your deployment by running the Cube CTL exposed command. Kubernetes then creates a service with a fixed type key for your pods, and the controller says, I need to attach an external load balancer with a public IP address chat service, so others outside the cluster can access it. In GKE, the load balancer is created as a network load balancer. Instead of issuing commands, you can provide a configuration file that tells Kubernetes what do you want your desired state to look like, and Kubernetes figures out how to do it. To get the file, you can run a Cube CTL get pods command as shown here to get a YAML file. In this case, the YAML file declares that you want three replicas of your engine next pod. It also defines a selector field, so the deployment knows how to group specific pods' replicas, and you could add a label to the pod templates, so they get selected. To run five replicas instead of three, all you do is update the deployment conflict file, and then run the Cube CTL apply command to use the updated config file.

## 3. Managing App Engine resources

* Our next section in the study guide concerns to management of App Engine resources, where we'll look at how to auto-scale App Engine instances. What are App Engine instances? Instances are the basic building blocks of App Engine, providing all the resources needed to successfully host your application. This includes the language runtime, the App Engine APIs, and your application's code and memory. Each instance includes a security layer to ensure that instances cannot inadvertently affect each other. Instances are the computing units that App Engine uses to automatically scale your application. At any given time, your application can be running on one instance or many instances with requests being spread across all of them. Instances are resident or dynamic. A dynamic instance starts up and shut down automatically based on the current needs. A resident instance runs all the time which can improve your application's performance. Both dynamic and resident instances instantiate the code included in an App Engine service version. If you use manual scaling for an app, the instances it runs on are resident instances. If you use either basic or automatic scaling, your app runs on dynamic instances. When you upload a version of a service, the app.ylm files specifies a scaling type and instance class to apply to every instance of that version. The scaling type controls how instances are created. The instance class determines compute resources, memory sizes and CPU speed, and pricing. There are three scaling types; manual, basic, and automatic. The available instance classes depend on the scaling type. Manual scaling uses resident instances that continuously runs a specified number of instances irrespective of the low-level. There's a lot of tasks such as complex initializations and applications that rely on the state of the memory over time. Automatic scaling uses dynamic instances. They get create a base on request rate, response latencies, and other application metrics. However, if you specify a minimum number of instances that number of instances run as residents businesses or additional instances are dynamic. Basic scaling uses dynamic instances. Each instance is created when the application reconsider a request. The instance will be turned down when the app becomes idle. Basic scaling is ideal for work that is intermittent or driven by user activity.

## 4. Managing data solutions

* Our next section deals with choosing the best options for managing your solution's data. In particular, we'll look at storage type options for managing cloud storage buckets. You can assign a life cycle management configuration to a bucket. The configuration contains a set of rules which apply to current and future objects in the bucket. When an object meets the criteria of one of the rules, cloud storage automatically performs its specified action on the object. Here are some example use cases. Downgrade the storage class of objects older than 365 days to cold line storage. Delete objects created before January 1, 2013. Keep only the three most recent versions of each object in a bucket with versioning enabled. The following actions are supported for lifecycle, delete, delete live and/or archived objects. This action can be applied to both versioned and non-versioned objects. In a bucket with versioning enabled, deleting a live object archives the object, or deleting an archived object believes object permanently. SetStorageClass, change the storage class of live and/or archived objects. This action can be applied to both versioned and non-versioned objects. The following conditions are supported for a lifecycle rule. Age, this condition is satisfied when an object reaches a specified age in days. CreatedBefore, this condition is satisfied when an object is created before midnight, the specified date and UTC is live. If the value is true, this life cycle conditions matches only live objects. If the value is false it matches only archive objects. MatchesStorageClass, this condition is satisfied when an object in the bucket is stored as a specified storage class. NumberOfNewerVersions, relevant only for versioned objects. If the value of this condition is set to n, an object satisfies the condition when there are at least n versions, including the live versions newer than n. For live objects, the number of newer versions is considered to be zero.

## 5. Managing networking resources

* Managing our Cloud solutions network resources. In this sub-session, we'll look at how to expand the CIDR block subnet. Before we begin, let's review some of the key requirements of a VPC network in the subnet. In a VPC network, each subnet must have a primary range in optionally up to five secondary ranges for an alias IP. Primary and secondary IP ranges must be RFC 1918 addresses. Within our VPC network, all primary and secondary IP addresses must be unique. But they don't need to be contiguous. For example, the primary arrange on a subnet can be 10.0.0.0/24 while the primary range of another subnet in the same network, can be 192.168.0.0/16. You can remove or replace a subnet secondary IP range only if no other instances are using that range. The primary IP range for the subnet can be expanded but not replaced or shrunk after a subnet has been created. The minimum primary or secondary brain size is eight IP addresses. In other words, the longest subnet mask you can use is /29.

## 6. Monitoring and logging

* Lastly, let's turn again to two very important topics; monitoring and logging. Section 4.6 covers tasks associated with monitoring your cloud solution. Making sure that it stays secure and healthy. Stackdriver aggregates metrics, logs, and events from your cloud infrastructure, giving you a rich set of observable data and metrics that can help developers and admins resolve security or performance issues work quickly. Several services including App Engine flexible, App Engine standard, and Kubernetes Engine have Stackdriver Monitoring built-in. For other services without Stackdriver Monitoring built-in, such as Compute Engine, there are monitoring engines that can be installed. Stackdriver Monitoring engines even exist for Amazon EC2 and non- [inaudible] services. This allows Stackdriver to provide a multi-cloud hybrid monitoring solution. You can also create and manage alerting policies with the Stackdriver Monitoring console, the Stackdriver Monitoring API and the Cloud SDK. Each policy specifies the following: conditions that identify an unhealthy state for a resource or a group of resources, optional notifications set their email, SMS or other channels to let your support team know that a resource is unhealthy. Optional documentation that can be included in some types of notifications to help your support team resolve the issue. When events trigger conditions in one of your alerting policies, Stackdriver Monitoring creates and displays an incident in the Stackdriver Monitoring console. If you set up notifications, Stackdriver Monitoring also sends notifications to people or third party notification services. Respondents can acknowledge receipt of the notification, but the incident remains open until resources are no longer in an unhealthy state. In the site reliability troubleshooting with Stackdriver APM lab in our final module, you'll have a chance to see Stackdriver at work and gain hands-on experience setting it up.

## 7. Resource links for Module

VM Images:  https://cloud.google.com/compute/docs/images

Creating, deleting, deprecating custom images:  https://cloud.google.com/compute/docs/images/create-delete-deprecate-private-images

Creating snapshots:  https://cloud.google.com/compute/docs/disks/create-snapshots

How App Engine instances are managed:  https://cloud.google.com/appengine/docs/standard/python/how-instances-are-managed

Object lifecycle management:  https://cloud.google.com/storage/docs/lifecycle

Expanding subnets:  https://cloud.google.com/vpc/docs/using-vpc#expand-subnet

Introduction to Alerting:  https://cloud.google.com/monitoring/alerts/

Managing alerting policies:  https://cloud.google.com/monitoring/alerts/using-alerting-ui